# Welcome to the AI4ME Cookbook | AI for Marine Ecosystems Cookbook
Useful information and code to help open science AI/ML efforts for marine ecosystems

# ***In Development***

## Workshop Brainstorm Session
### Workshop Goal: TBD
- Equip the team with a shared understanding of object detection workflows
- define how annotations fit into the model lifecycle
- develop a clear plan to maximize team efficiency

### Workshop Prep -  Clarify objectives/goals, priorities, and expectations.
- What is the overall strategy for object detection in ESD/ARP
  - how can we use our team most effectively
- What are primary object detection use cases
  - Urchin
  - ESA Corals
  - So on
- How is the annotation team currently being used
  - What are the current challenges
  - annotation scenarios examples
- What decisions need to be made regarding annotation tools, formats, or workflows?
- Are there specific datasets, models, or deployment goals?
- Intrest in more deep dives/hands-on sessions?
- timeline for integrating object detection into operational workflows

### Draft Agenda

#### 1. Overview
- Quick primer on object detection pipeline (data → annotation → model training → deployment)
- Role of annotations in model performance (importance of quality & consistency)
- Where to find data, resouces, and so on?

#### **Note:** AI/ML is non-linear. 
Performance of the model and its output is not proportional to the input. Not just data input, but effort as well. Experimentation is key. [link](https://developers.google.com/machine-learning/managing-ml-projects/planning)

#### 2. Models, Data & Annotation Strategies & Tools
- Best practices for efficient annotation workflow
- Review tools(CVAT, Label Studio, Viame) and discuss pros/cons
- Discuss integrating QA/QC checks and techniques
- 
#### 3. Hands On 
- Exploratory data analysis(EDA)
- Annotation 
- Dataset Prep
- Model Development & Training
- Model Deployment

### Q&A / Roundtable
- Whats slowing down annotation efforts and how can we improve our systems
- How can annotations be better tailored for model use?
- Ideas for improving annotation throughput without sacrificing quality (inital model to create predictions for human verification)

### Next Steps
- another workshop?
- user exercises
